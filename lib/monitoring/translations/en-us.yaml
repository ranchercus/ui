generic:
  cpu: CPU
  memory: Memory
  hours: Hours
  noData: No Data

metrics:
  cluster-cpu-usage: CPU Utilization
  cluster-cpu-load: Load Average
  cluster-memory-usage: Memory Utilization
  cluster-fs-usage-percent: Disk Utilization
  cluster-disk-io: Disk I/O
  cluster-network-io: Network I/O
  cluster-network-packet: Network Packets
  etcd-db-bytes-sum: DB Size
  etcd-grpc-client: GRPC Client Traffic
  etcd-peer-traffic: Peer Traffic
  etcd-raft-proposals: Raft Proposals
  etcd-rpc-rate: RPC Rate
  etcd-stream: Active Streams
  etcd-sync-duration: Disk Sync Duration
  apiserver-request-count: API Server Request Rate
  apiserver-request-latency: API Server Request Latency
  scheduler-e-2-e-scheduling-latency-seconds-quantile: Scheduler E2E Scheduling Latency
  scheduler-pod-unscheduler: Scheduling Failed Pods
  scheduler-total-preemption-attempts: Scheduler Preemption Attempts
  controllermanager-queue-depth: Controller Manager Queue Depth
  ingresscontroller-nginx-connection: Ingress Controller Connections
  ingresscontroller-request-process-time: Ingress Controller Request Process Time
  node-cpu-load: Load Average
  node-cpu-usage: CPU Utilization
  node-memory-usage: Memory Utilization
  node-fs-usage-percent: Disk Utilization
  node-disk-io: Disk I/O
  node-network-io: Network I/O
  node-network-packet: Network Packets
  etcd-leader-change: Leader Change
  etcd-disk-operate: Disk Operations
  fluentd-buffer-queue-length: Fluentd Buffer Queue Rate
  fluentd-output-errors: Fluentd Output Errors Rate
  fluentd-output-record-number: Fluentd Output Rate
  fluentd-input-record-number: Fluentd Input Rate

ingressResponse:
  host: Host
  path: Path
  responseTime: Response Time
  noData: No Data
  noMatch: No records match the current search
  detail: Top 10 ingress upstream response time
  title: Ingress Upstream Response Time

etcd:
  hasLeader:
    label: Etcd has a leader
  leaderChange:
    label: Number of leader changes
  failedProposals:
    label: Number of failed proposals

clusterDashboard:
  title: Dashboard
  sections:
    cluster: Cluster Metrics
    etcd: Etcd Metrics
    k8s: Kubernetes Components Metrics
    rancher: '{appName} Logging Metrics'
    node: Node Metrics
  noRancherComponents: '{appName} Logging is not enabled in this cluster or not enough data for graph.'
  cpu: CPU
  memory: Memory
  pods: Pods
  value: Value
  more: More
  subtitle:
    reserved: "{used} of {total} Reserved"
    used: "{used} of {total} Used"
  enableMonitoring: Enable Monitoring to see live metrics
  upgradeAvailable: "Monitoring {version} Upgrade Available"
  monitoringNotReady: Monitoring API is not ready
  node: Nodes
  etcd: Etcd
  scheduler: Scheduler
  controllerManager: Controller Manager
  alert:
    node: "Alert: Node {node} is not active."
    component: "Alert: Component {component} is unhealthy."
  liveTitle: "{used} of {total} Used"
  reserved: Reserved

monitoringPage:
  update: Update configuration
  version: Monitoring Version
  upgrade: Upgrade monitoring to the latest version {version}
  upgradeAvailable: "({version} Upgrade Available)"
  confirmDisable: "Are you sure?  Click again to really disable monitoring."
  disable: Disable Monitoring
  enableActionLabel: Enable Monitoring
  toUpdate:
    cluster: Cluster level monitoring is enabled.
    project: Project level monitoring is enabled.
  insufficientSize:
    prometheus:
      cpu: Please make sure you have at least one node has {cpu} milli CPUs available to enable Prometheus workload.
      memory: Please make sure you have at least one node has {memory} MiB of memory available to enable Prometheus workload.
      all: Please make sure you have at least one node has {cpu} milli CPUs and {memory} MiB of memory available to enable Prometheus workload.
    selectors:
      cpu: Please make sure you have at least one node matches node selectors has {cpu} milli CPUs available to enable Prometheus workload.
      memory: Please make sure you have at least one node matches node selectors has {memory} MiB of memory available to enable Prometheus workload.
      all: Please make sure you have at least one node matches node selectors has {cpu} milli CPUs and {memory} MiB of memory available to enable Prometheus workload.
    total:
      cpu: Please make sure you have at least {cpu} milli CPUs available to enable monitoring.
      memory: Please make sure you have at least {memory} MiB of memory available to enable monitoring.
      all: Please make sure you have at least {cpu} milli CPUs and {memory} MiB of memory available to enable monitoring.
  clusterNotEnabled: Cluster level monitoring is not enabled. Only custom metrics will be collected.
  prometheus: Monitoring is not enabled yet, click the Save button below to enable it.
  resourceLimitsHelp: 'When enabling cluster monitoring, you need to ensure your worker nodes and Prometheus pod have enough resources. Please visit <a href="https://rancher.com/docs/rancher/v2.x/en/cluster-admin/tools/monitoring/#resource-consumption" target="_blank" rel="nofollow noreferrer">the Rancher docs</a> for suggested resource limits.'
  config:
    types:
      none: None
      prometheus: Prometheus
    header: Prometheus Configuration
    prometheus:
      cpuLimit:
        label: Prometheus CPU Limit
        placeholder: e.g. 1000
        unit: milli CPUs
      cpuRequest:
        label: Prometheus CPU Reservation
        placeholder: e.g. 1000
        unit: milli CPUs
      memoryLimit:
        label: Prometheus Memory Limit
        placeholder: e.g. 1000
      memoryRequest:
        label: Prometheus Memory Reservation
        placeholder: e.g. 1000
      enablePersistence:
        label: Enable Persistent Storage for Prometheus
      size:
        label: Prometheus Persistent Volume Size
        placeholder: e.g. 50Gi
      storageClass:
        label: Default StorageClass for Prometheus
    grafana:
      enablePersistence:
        label: Enable Persistent Storage for Grafana
      size:
        label: Grafana Persistent Volume Size
        placeholder: e.g. 10Gi
      storageClass:
        label: Default StorageClass for Grafana
    retention:
      label: Data Retention
    storageClass:
      label: Storage Class
    operator:
      memoryLimit:
        label: Prometheus Operator Memory Limit
        placeholder: e.g. 500
    nodeexporter:
      label: Node Exporter Host Port
      enable: Enable Node Exporter
      cpuLimit:
        label: Node Exporter CPU Limit
        placeholder: e.g. 200
        unit: milli CPUs
      memoryLimit:
        label: Node Exporter Memory Limit
        placeholder: e.g. 200
  nodeSelector:
    addSelectorLabel: Add Selector
    helpText: Select the nodes where monitoring related workloads will be scheduled to
  cluster:
    title: Cluster Monitoring Configuration
    disabled: Monitoring is disabled in the current cluster.
    toDisable: Monitoring is enabled. Click the Save button below will disable monitoring in current cluster.
  project:
    title: Project Monitoring Configuration
    disabled: Monitoring is disabled in the current project.
    toDisable: Monitoring is enabled. Click the Save button below will disable monitoring in current project.
